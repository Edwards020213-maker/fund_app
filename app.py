import streamlit as st
import pandas as pd
import requests
import akshare as ak
import datetime
import os

# --- æ ¸å¿ƒé€»è¾‘é…ç½® (ç›´æ¥å¤ç”¨ V7.0) ---
PROXY_MAP = {
    # ... (ä¿æŒåŸæœ¬ V7.0 çš„ PROXY_MAP å­—å…¸å†…å®¹ï¼Œä¸ºäº†ç¯‡å¹…è¿™é‡Œçœç•¥ï¼Œè¯·åŠ¡å¿…å®Œæ•´å¤åˆ¶è¿›æ¥) ...
    # === å¤§å®—å•†å“/è´µé‡‘å± ===
    "é»„é‡‘": "518880", "ä¸Šæµ·é‡‘": "518600", "è±†ç²•": "159985",
    "æœ‰è‰²": "512400", "åŒ–å·¥": "516020", "çŸ³åŒ–": "516020",
    "çŸ³æ²¹": "561360", "æ²¹æ°”": "513350", "ç…¤ç‚­": "515220",
    # === å®½åŸº ===
    "æ²ªæ·±300": "510300", "ä¸Šè¯50": "510050", "ä¸­è¯500": "510500",
    "ç§‘åˆ›50": "588000", "åˆ›ä¸šæ¿": "159915", "å¾®ç›˜": "563300",
    # === è¡Œä¸š ===
    "åŠå¯¼ä½“": "512480", "èŠ¯ç‰‡": "159995", "äººå·¥æ™ºèƒ½": "159819",
    "æ¸¸æˆ": "159869", "ä¼ åª’": "512980", "å…‰ä¼": "515790",
    "æ–°èƒ½æº": "515030", "ç™½é…’": "161725", "åŒ»ç–—": "512170",
    "åŒ»è¯": "512010", "è¯åˆ¸": "512000", "é“¶è¡Œ": "512800",
    # === è·¨å¢ƒ ===
    "çº³æ–¯è¾¾å…‹": "513100", "çº³æŒ‡": "513100", "æ ‡æ™®500": "513500",
    "æ’ç”Ÿç§‘æŠ€": "513180", "æ’ç”Ÿäº’è”ç½‘": "513330", "ä¸­æ¦‚äº’è”": "513050",
    "æ’ç”ŸæŒ‡æ•°": "159920", "æ—¥ç»": "513520",
}

# --- å·¥å…·å‡½æ•° (å¤ç”¨ V7.0) ---
def get_tencent_code(symbol):
    s = str(symbol).strip().upper()
    if s.isalpha(): return f"us{s}"
    if len(s) == 5 and s.isdigit(): return f"hk{s}"
    if len(s) == 6 and s.isdigit():
        if s.startswith(('5','6','9')): return f"sh{s}"
        if s.startswith(('0','1','2','3')): return f"sz{s}"
    return None

def fetch_quotes_universal(code_list):
    if not code_list: return {}, 0.0
    unique_codes = list(set(code_list))
    t_codes = []
    map_ref = {}
    need_fx = False
    
    for c in unique_codes:
        tc = get_tencent_code(c)
        if tc:
            key = f"s_{tc}"
            t_codes.append(key)
            map_ref[key] = c
            if "us" in tc: need_fx = True
    
    if need_fx: t_codes.append("s_usUSDCNH")
    
    res_dict = {}
    fx_change = 0.0
    
    # ç®€å•è¯·æ±‚
    try:
        url = f"http://qt.gtimg.cn/q={','.join(t_codes)}"
        r = requests.get(url, timeout=3)
        r.encoding = 'gbk'
        for line in r.text.split(';'):
            if '=' not in line: continue
            k, v = line.split('=', 1)
            data = v.strip('"').split('~')
            if len(data) < 6: continue
            
            if "s_usUSDCNH" in k:
                try: fx_change = float(data[5])
                except: pass
            else:
                key_clean = k.split('v_')[-1]
                raw = map_ref.get(key_clean)
                if raw:
                    try: res_dict[raw] = float(data[5])
                    except: pass
    except: pass
    return res_dict, fx_change

def get_fund_info_tencent(fund_code):
    try:
        url = f"http://qt.gtimg.cn/q=jj{fund_code}"
        r = requests.get(url, timeout=2)
        r.encoding = 'gbk'
        text = r.text
        if '="' in text:
            return text.split('="')[1].strip('";').split('~')[1]
    except: pass
    return f"åŸºé‡‘{fund_code}"

# --- åˆ†æé€»è¾‘ (æ”¹é€ ä¸ºé€‚é… Streamlit) ---
def analyze_fund(fund_code):
    # 1. æ‹¿åå­—
    fund_name = get_fund_info_tencent(fund_code)
    
    # 2. å€ºåˆ¸åˆ¤æ–­
    if "å€º" in fund_name and "å¯è½¬å€º" not in fund_name:
        return {"name": fund_name, "val": 0.0, "method": "ğŸ›¡ï¸ å€ºåˆ¸åŸºé‡‘", "detail": "æ³¢åŠ¨æå°"}
        
    # 3. ä»£ç†æ˜ å°„
    for kw, proxy in PROXY_MAP.items():
        if kw in fund_name:
            q, _ = fetch_quotes_universal([proxy])
            return {"name": fund_name, "val": q.get(proxy, 0.0), "method": "âš¡ è¡Œä¸šé”šå®š", "detail": f"è¿½è¸ª {kw}({proxy})"}
            
    # 4. æŸ¥æŒä»“
    holdings_df = pd.DataFrame()
    try:
        cur_year = datetime.datetime.now().year
        for y in [cur_year, cur_year-1]:
            df = ak.fund_portfolio_hold_em(symbol=fund_code, date=str(y))
            if not df.empty:
                holdings_df = df[df['å­£åº¦'] == df['å­£åº¦'].max()].copy()
                break
    except: pass
    
    # 5. è®¡ç®—
    if not holdings_df.empty:
        stocks = holdings_df['è‚¡ç¥¨ä»£ç '].astype(str).tolist()
        weights = pd.to_numeric(holdings_df['å å‡€å€¼æ¯”ä¾‹'], errors='coerce') / 100
        quotes, fx = fetch_quotes_universal(stocks)
        
        total_w = 0
        total_c = 0
        us_count = 0
        for i, s in enumerate(stocks):
            if s in quotes:
                w = weights.iloc[i]
                c = quotes[s]
                if s.isalpha(): 
                    c += fx
                    us_count += 1
                total_c += w * c
                total_w += w
                
        if total_w > 0.05:
            est = total_c / total_w
            if us_count > 3:
                return {"name": fund_name, "val": est, "method": "ğŸ‡ºğŸ‡¸ ç¾è‚¡ç©¿é€", "detail": f"æ˜¨æ”¶+æ±‡ç‡({fx:+.2f}%)"}
            else:
                return {"name": fund_name, "val": est, "method": "ğŸ“ˆ æŒä»“ç©¿é€", "detail": f"åŸºäº {len(stocks)} åªæŒä»“"}

    return {"name": fund_name, "val": 0.0, "method": "âŒ æ— æ³•ä¼°ç®—", "detail": "æ— æ•°æ®"}

# --- Streamlit ç•Œé¢ä»£ç  ---

st.set_page_config(page_title="åŸºé‡‘ä¼°å€¼åŠ©æ‰‹", page_icon="ğŸ“ˆ")

st.title("ğŸ“ˆ åŸºé‡‘ç›˜ä¸­å®æ—¶ä¼°å€¼ V7.0")
st.markdown("æ”¯æŒï¼š**è‚¡ç¥¨å‹ / ETFè”æ¥ / QDII / é»„é‡‘ / è¡Œä¸šæŒ‡æ•°**")

# è¾“å…¥æ¡†
default_codes = "013403, 005827, 000834, 000217, 007911"
user_input = st.text_input("è¯·è¾“å…¥åŸºé‡‘ä»£ç  (é€—å·åˆ†éš”):", value=default_codes)

if st.button("å¼€å§‹ä¼°å€¼", type="primary"):
    codes = [c.strip() for c in user_input.replace("ï¼Œ", ",").split(",") if c.strip()]
    
    if not codes:
        st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ä»£ç ")
    else:
        # åˆ›å»ºä¸€ä¸ªè¿›åº¦æ¡
        progress_bar = st.progress(0)
        results = []
        
        for i, code in enumerate(codes):
            res = analyze_fund(code)
            results.append({
                "ä»£ç ": code,
                "åç§°": res['name'].replace("å‘èµ·å¼","").replace("è”æ¥","").replace("äººæ°‘å¸","")[:10],
                "ä¼°å€¼": res['val'],
                "æ¨¡å¼": res['method'],
                "è¯¦æƒ…": res['detail']
            })
            progress_bar.progress((i + 1) / len(codes))
            
        progress_bar.empty() # æ¸…é™¤è¿›åº¦æ¡
        
        # å±•ç¤ºç»“æœ
        st.subheader("ğŸ“Š ä¼°å€¼ç»“æœ")
        
        # å°†ç»“æœè½¬æ¢ä¸º DataFrame ä»¥ä¾¿ç¾åŒ–å±•ç¤º
        for row in results:
            val = row['ä¼°å€¼']
            color = "gray"
            if val > 0: color = "red"
            elif val < 0: color = "green"
            
            # ä½¿ç”¨å¡ç‰‡å¼å¸ƒå±€å±•ç¤º
            col1, col2, col3 = st.columns([2, 1, 2])
            with col1:
                st.markdown(f"**{row['åç§°']}** ({row['ä»£ç ']})")
                st.caption(row['æ¨¡å¼'])
            with col2:
                st.markdown(f":{color}[**{val:+.2f}%**]")
            with col3:
                st.text(row['è¯¦æƒ…'])
            st.divider()